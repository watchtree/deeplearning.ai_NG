{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks: Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tree/Downloads/yes/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/tree/Downloads/yes/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad, pad), (0, 0)), 'constant' , constant_values = 0)\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.pad填充专用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (4, 3, 3, 2)\n",
      "x_pad.shape = (4, 7, 7, 2)\n",
      "x[1,1] = [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] = [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33b7228438>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\", x.shape)\n",
    "print (\"x_pad.shape =\", x_pad.shape)\n",
    "print (\"x[1,1] =\", x[1,1])\n",
    "print (\"x_pad[1,1] =\", x_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single step of convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    s = np.multiply(a_slice_prev, W) + b\n",
    "    Z = np.sum(s)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -23.16021220252078\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    (f,f,n_C_prev, n_C) = W.shape \n",
    "    \n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    n_H = 1 + int((n_H_prev + 2 * pad -f) / stride)\n",
    "    n_W = 1 + int((n_W_prev + 2 * pad -f) / stride)\n",
    "    \n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "    \n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        for h in range(n_H):\n",
    "            for w in range(n_W):\n",
    "                for c in range(n_C):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end,:]\n",
    "                    \n",
    "                    Z[i, h, w, c] = np.sum(np.multiply(a_slice_prev, W[:,:,:,c]) + b[:,:,:,c])\n",
    "    \n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 0.15585932488906465\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 1}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "    \n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "    \n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))              \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    if mode == \"max\":\n",
    "                        A[i,h,w,c] = np.max(a_prev_slice)\n",
    "                    if mode == \"average\":\n",
    "                        A[i,h,w,c] = np.mean(a_prev_slice)\n",
    "                    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A = [[[[1.74481176 1.6924546  2.10025514]]]\n",
      "\n",
      "\n",
      " [[[1.19891788 1.51981682 2.18557541]]]]\n",
      "\n",
      "mode = average\n",
      "A = [[[[-0.09498456  0.11180064 -0.14263511]]]\n",
      "\n",
      "\n",
      " [[[-0.09525108  0.28325018  0.33035185]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 4, 4, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 4}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A =\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A =\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ, cache):\n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve information from \"cache\"\n",
    "    (A_prev, W, b, hparameters) = cache\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve dimensions from W's shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "    \n",
    "    # Retrieve information from \"hparameters\"\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "    \n",
    "    # Retrieve dimensions from dZ's shape\n",
    "    (m, n_H, n_W, n_C) = dZ.shape\n",
    "    \n",
    "    # Initialize dA_prev, dW, db with the correct shapes\n",
    "    dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
    "    dW = np.zeros((f, f, n_C_prev, n_C))\n",
    "    db = np.zeros((1, 1, 1, n_C))\n",
    "\n",
    "    # Pad A_prev and dA_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
    "\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select ith training example from A_prev_pad and dA_prev_pad\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        da_prev_pad = dA_prev_pad[i]\n",
    "        \n",
    "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
    "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
    "                for c in range(n_C):           # loop over the channels of the output volume\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\"\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Use the corners to define the slice from a_prev_pad\n",
    "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
    "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
    "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
    "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
    "                    \n",
    "        # Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
    "        dA_prev[i, :, :, :] = dA_prev_pad[i, pad:-pad, pad:-pad, :]\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 9.608990675868995\n",
      "dW_mean = 10.581741275547563\n",
      "db_mean = 76.37106919563735\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_window(x):\n",
    "    mask = (x == np.max(x))\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  [[ 1.62434536 -0.61175641 -0.52817175]\n",
      " [-1.07296862  0.86540763 -2.3015387 ]]\n",
      "mask =  [[ True False False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(2,3)\n",
    "mask = create_mask_from_window(x)\n",
    "print('x = ', x)\n",
    "print(\"mask = \", mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average pooling - backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_value(dz, shape):\n",
    "    \"\"\"\n",
    "    Distributes the input value in the matrix of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    dz -- input scalar\n",
    "    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz\n",
    "    \n",
    "    Returns:\n",
    "    a -- Array of size (n_H, n_W) for which we distributed the value of dz\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from shape (≈1 line)\n",
    "    (n_H, n_W) = shape\n",
    "    \n",
    "    # Compute the value to distribute on the matrix (≈1 line)\n",
    "    average = dz / (n_H * n_W)\n",
    "    \n",
    "    # Create a matrix where every entry is the \"average\" value (≈1 line)\n",
    "    a = np.ones(shape) * average\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distributed value = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "a = distribute_value(2, (2,2))\n",
    "print('distributed value =', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dA, cache, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the backward pass of the pooling layer\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A\n",
    "    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters \n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Retrieve information from cache (≈1 line)\n",
    "    (A_prev, hparameters) = cache\n",
    "    \n",
    "    # Retrieve hyperparameters from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters['stride']\n",
    "    f = hparameters['f']\n",
    "    \n",
    "    # Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
    "    m, n_H, n_W, n_C = dA.shape\n",
    "    \n",
    "    # Initialize dA_prev with zeros (≈1 line)\n",
    "    dA_prev = np.zeros_like(A_prev)\n",
    "    \n",
    "    for i in range(m):                       # loop over the training examples\n",
    "        \n",
    "        # select training example from A_prev (≈1 line)\n",
    "        a_prev = A_prev[i]\n",
    "        \n",
    "        for h in range(n_H):                   # loop on the vertical axis\n",
    "            for w in range(n_W):               # loop on the horizontal axis\n",
    "                for c in range(n_C):           # loop over the channels (depth)\n",
    "                    \n",
    "                    # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    # Compute the backward propagation in both modes.\n",
    "                    if mode == \"max\":\n",
    "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        mask = create_mask_from_window(a_prev_slice)\n",
    "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end,c] += mask *dA[i, vert_start, horiz_start, c]\n",
    "\n",
    "                    elif mode == \"average\":\n",
    "                        da = dA[i, vert_start, horiz_start, c]\n",
    "                        # Define the shape of the filter as fxf (≈1 line)\n",
    "                        shape = (f, f)\n",
    "                        # Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)\n",
    "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
    "                        \n",
    "    ### END CODE ###\n",
    "    \n",
    "    # Making sure your output shape is correct\n",
    "    assert(dA_prev.shape == A_prev.shape)\n",
    "    \n",
    "    return dA_prev   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.          0.        ]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.14571390272918056\n",
      "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "hparameters = {\"stride\" : 1, \"f\": 2}\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "\n",
    "dA_prev = pool_backward(dA, cache, mode = \"max\")\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "print()\n",
    "dA_prev = pool_backward(dA, cache, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
