{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "#显示图片用\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras:基于Python的深度学习库** \n",
    "\n",
    "Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：\n",
    "\n",
    "\n",
    "1. 简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）\n",
    "2. 支持CNN和RNN，或二者的结合\n",
    "3. 无缝CPU和GPU切换\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The identity block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 =filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(filters = F1, kernel_size=(1,1), strides=(1,1), padding='valid', name = conv_name_base+'2a', kernel_initializer=glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding='same', name = conv_name_base+'2b', kernel_initializer=glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis =3 ,name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(filters=F3, kernel_size =(1,1), strides=(1, 1), padding = 'valid', name = conv_name_base+'2c',kernel_initializer=glorot_uniform(seed= 0))(X)\n",
    "    X = BatchNormalization(axis=3, name= bn_name_base+'2c')(X)\n",
    "    \n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.9482299 0.        1.1610144 2.747859  0.        1.36677  ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s =2):\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    X = Conv2D(F1, (1,1), strides = (s,s), name = conv_name_base + '2a', padding='valid', kernel_initializer=glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis =3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F2, (f,f), strides = (1,1), name = conv_name_base + '2b', padding='same', kernel_initializer=glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis =3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(F3, (1,1), strides = (1,1), name = conv_name_base + '2c', padding='valid', kernel_initializer=glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis =3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    X_shortcut = Conv2D(F3, (1,1), strides=(s, s), name = conv_name_base + '1' , padding= 'valid', kernel_initializer= glorot_uniform(seed = 0))(X_shortcut)\n",
    "    X_shortcut =BatchNormalization(axis =3, name= bn_name_base + '1')(X_shortcut)\n",
    "    \n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X  = Activation('relu')(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.09018461 1.2348977  0.46822017 0.0367176  0.         0.655166  ]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your first ResNet model (50 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    X = Conv2D(64,(7,7), strides = (2,2) , name = 'conv1', kernel_initializer=glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3,3), strides=(2,2))(X)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
